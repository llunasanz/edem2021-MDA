{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.Spark_SQL_Advanced.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tv0AmHi926F7"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq9d0x1OTh2N"
      },
      "source": [
        "# Prerrequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_DQBVj_KNvL"
      },
      "source": [
        "Installing Spark\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEbGSM3_NM-z"
      },
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!pip -q install findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP_HtvSAj4sI"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhjOxtJWb5Y1"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G28MgeRJHKJ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d9582db7-09cd-40f9-cb49-205a54e43da6"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# create the session\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark.version"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.2.0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNiYuI5dGo8Y"
      },
      "source": [
        "Creating tunnel</br>\n",
        "**To Check the Spark UI, open the URL printed by running the above command : https://######/jobs/, /SQL/**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4-7fXZiGmqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac2ecdce-b772-47a6-d2cd-cfa55a054a64"
      },
      "source": [
        " from google.colab.output import eval_js\n",
        " print(eval_js(\"google.colab.kernel.proxyPort(4040)\") + \"jobs/\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://xwkkhjduta-496ff2e9c6d22116-4040-colab.googleusercontent.com/jobs/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z0h3dF9Vg4X"
      },
      "source": [
        "# Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBDin-0sXgyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e67864-404e-4a3d-9c5f-b50a0c9c04e9"
      },
      "source": [
        "!mkdir -p /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/characters.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/planets.csv -P /dataset\n",
        "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/species.csv -P /dataset\n",
        "!ls /dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bank.csv  characters.csv  planets.csv  species.csv  vehicles.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Zwm3NRXS_I"
      },
      "source": [
        "# Windows Partitioning\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o6f6QOjTcZ"
      },
      "source": [
        "## Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USrsDETtstv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55e17ad-4ca7-48c2-9e4a-be2ff9fe2ab9"
      },
      "source": [
        "!head /dataset/bank.csv"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"age\";\"job\";\"marital\";\"education\";\"default\";\"balance\";\"housing\";\"loan\";\"contact\";\"day\";\"month\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"y\"\n",
            "30;\"unemployed\";\"married\";\"primary\";\"no\";1787;\"no\";\"no\";\"cellular\";19;\"oct\";79;1;-1;0;\"unknown\";\"no\"\n",
            "33;\"services\";\"married\";\"secondary\";\"no\";4789;\"yes\";\"yes\";\"cellular\";11;\"may\";220;1;339;4;\"failure\";\"no\"\n",
            "35;\"management\";\"single\";\"tertiary\";\"no\";1350;\"yes\";\"no\";\"cellular\";16;\"apr\";185;1;330;1;\"failure\";\"no\"\n",
            "30;\"management\";\"married\";\"tertiary\";\"no\";1476;\"yes\";\"yes\";\"unknown\";3;\"jun\";199;4;-1;0;\"unknown\";\"no\"\n",
            "59;\"blue-collar\";\"married\";\"secondary\";\"no\";0;\"yes\";\"no\";\"unknown\";5;\"may\";226;1;-1;0;\"unknown\";\"no\"\n",
            "35;\"management\";\"single\";\"tertiary\";\"no\";747;\"no\";\"no\";\"cellular\";23;\"feb\";141;2;176;3;\"failure\";\"no\"\n",
            "36;\"self-employed\";\"married\";\"tertiary\";\"no\";307;\"yes\";\"no\";\"cellular\";14;\"may\";341;1;330;2;\"other\";\"no\"\n",
            "39;\"technician\";\"married\";\"secondary\";\"no\";147;\"yes\";\"no\";\"cellular\";6;\"may\";151;2;-1;0;\"unknown\";\"no\"\n",
            "41;\"entrepreneur\";\"married\";\"tertiary\";\"no\";221;\"yes\";\"no\";\"unknown\";14;\"may\";57;2;-1;0;\"unknown\";\"no\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjPpxRyJYA1h"
      },
      "source": [
        "Reading data from `bank.csv` file to a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnbafeFCVk8d"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "bank_df = spark.read.format(\"csv\") \\\n",
        "  .option(\"sep\", \";\") \\\n",
        "  .option(\"inferSchema\", \"true\") \\\n",
        "  .option(\"header\", \"true\") \\\n",
        "  .load(\"/dataset/bank.csv\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxhLiwwXk6kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d4fd1f-4ae4-403e-ee29-f2d51769e0a9"
      },
      "source": [
        "bank_df.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|          job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "| 30|   unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
            "| 33|     services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
            "| 35|   management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
            "| 30|   management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n",
            "| 59|  blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n",
            "| 35|   management| single| tertiary|     no|    747|     no|  no|cellular| 23|  feb|     141|       2|  176|       3| failure| no|\n",
            "| 36|self-employed|married| tertiary|     no|    307|    yes|  no|cellular| 14|  may|     341|       1|  330|       2|   other| no|\n",
            "| 39|   technician|married|secondary|     no|    147|    yes|  no|cellular|  6|  may|     151|       2|   -1|       0| unknown| no|\n",
            "| 41| entrepreneur|married| tertiary|     no|    221|    yes|  no| unknown| 14|  may|      57|       2|   -1|       0| unknown| no|\n",
            "| 43|     services|married|  primary|     no|    -88|    yes| yes|cellular| 17|  apr|     313|       1|  147|       2| failure| no|\n",
            "| 39|     services|married|secondary|     no|   9374|    yes|  no| unknown| 20|  may|     273|       1|   -1|       0| unknown| no|\n",
            "| 43|       admin.|married|secondary|     no|    264|    yes|  no|cellular| 17|  apr|     113|       2|   -1|       0| unknown| no|\n",
            "| 36|   technician|married| tertiary|     no|   1109|     no|  no|cellular| 13|  aug|     328|       2|   -1|       0| unknown| no|\n",
            "| 20|      student| single|secondary|     no|    502|     no|  no|cellular| 30|  apr|     261|       1|   -1|       0| unknown|yes|\n",
            "| 31|  blue-collar|married|secondary|     no|    360|    yes| yes|cellular| 29|  jan|      89|       1|  241|       1| failure| no|\n",
            "| 40|   management|married| tertiary|     no|    194|     no| yes|cellular| 29|  aug|     189|       2|   -1|       0| unknown| no|\n",
            "| 56|   technician|married|secondary|     no|   4073|     no|  no|cellular| 27|  aug|     239|       5|   -1|       0| unknown| no|\n",
            "| 37|       admin.| single| tertiary|     no|   2317|    yes|  no|cellular| 20|  apr|     114|       1|  152|       2| failure| no|\n",
            "| 25|  blue-collar| single|  primary|     no|   -221|    yes|  no| unknown| 23|  may|     250|       1|   -1|       0| unknown| no|\n",
            "| 31|     services|married|secondary|     no|    132|     no|  no|cellular|  7|  jul|     148|       1|  152|       1|   other| no|\n",
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHDroSQ1ZQSB"
      },
      "source": [
        "Get the balance of the two youngest people by job\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BEWmhhYqxp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283090f2-6d85-4330-80d2-7cacdaa40893"
      },
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "byJob = Window.partitionBy(\"job\").orderBy(\"age\")\n",
        "\n",
        "bank_df \\\n",
        "  .withColumn(\"new_column_job\", row_number().over(byJob)) \\\n",
        "  .filter(col(\"new_column_job\") <= 2) \\\n",
        "  .select(\"age\", \"job\", \"balance\") \\\n",
        "  .orderBy(\"job\", \"age\") \\\n",
        "  .show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+-------+\n",
            "|age|          job|balance|\n",
            "+---+-------------+-------+\n",
            "| 22|       admin.|   4111|\n",
            "| 23|       admin.|      5|\n",
            "| 23|  blue-collar|    817|\n",
            "| 23|  blue-collar|   8627|\n",
            "| 23| entrepreneur|      4|\n",
            "| 25| entrepreneur|  16874|\n",
            "| 26|    housemaid|    543|\n",
            "| 26|    housemaid|   -759|\n",
            "| 23|   management|    736|\n",
            "| 24|   management|    172|\n",
            "| 24|      retired|    366|\n",
            "| 35|      retired|    285|\n",
            "| 25|self-employed|    453|\n",
            "| 26|self-employed|    211|\n",
            "| 21|     services|    361|\n",
            "| 21|     services|   1903|\n",
            "| 19|      student|      0|\n",
            "| 19|      student|    103|\n",
            "| 22|   technician|    333|\n",
            "| 23|   technician|    598|\n",
            "+---+-------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzU_4EjAjZgh"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV-NchsMsHvF"
      },
      "source": [
        "Using the dataframe built from `bank.csv`file, get the TOP 3 of maximum balance by marital\n",
        "Obtén el Top 3 de máximos balances por estado civil\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgireGq6YWEj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX0FXU7JawRm"
      },
      "source": [
        "## Exercise 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBtPRPnVmpGM"
      },
      "source": [
        "Load `vehicles.csv` file into a DataFrame\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYPt59chwJUw"
      },
      "source": [
        "!head /dataset/vehicles.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCDo_-PiaEVl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCDfqm_UxUcn"
      },
      "source": [
        "For each vehicle, get the difference in price (`cost_in_credits`) for each product compared to the cheapest product in the same vehicle class\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n2R6MJlxP4w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GUV9KLzqR-4"
      },
      "source": [
        "# Joins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZw41ki6kc3p"
      },
      "source": [
        "## Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAzx5B5IkVeP"
      },
      "source": [
        "1. Create dataframes for files `characters.csv` and `planets.csv`\n",
        "2. Get the planet gravity for each character, selecting only the character name, planet name and gravity.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMlJTJzTkC2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3558d75c-aca6-4293-f3dc-306c571ada81"
      },
      "source": [
        "charactersDF = spark.read.format(\"csv\")\\\n",
        ".option(\"sep\", \",\")\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".option(\"header\", \"true\")\\\n",
        ".load(\"/dataset/characters.csv\")\n",
        "\n",
        "charactersDF.printSchema()\n",
        "\n",
        "planetsDF = spark.read.format(\"csv\")\\\n",
        ".option(\"sep\", \";\")\\\n",
        ".option(\"inferSchema\", \"true\")\\\n",
        ".option(\"header\", \"true\")\\\n",
        ".load(\"/dataset/planets.csv\")\n",
        "\n",
        "planetsDF.printSchema()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- height: string (nullable = true)\n",
            " |-- mass: string (nullable = true)\n",
            " |-- hair_color: string (nullable = true)\n",
            " |-- skin_color: string (nullable = true)\n",
            " |-- eye_color: string (nullable = true)\n",
            " |-- birth_year: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- homeworld: string (nullable = true)\n",
            " |-- species: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- rotation_period: string (nullable = true)\n",
            " |-- orbital_period: string (nullable = true)\n",
            " |-- diameter: string (nullable = true)\n",
            " |-- climate: string (nullable = true)\n",
            " |-- gravity: string (nullable = true)\n",
            " |-- terrain: string (nullable = true)\n",
            " |-- surface_water: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Without columns names changed\n",
        "charactersDF\\\n",
        ".join(broadcast(planetsDF))\\\n",
        ".select(charactersDF.name, planetsDF.name, planetsDF.gravity)\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMyhYEHyJQBK",
        "outputId": "9e1fca70-8a52-49d1-eaf7-327c4de6e9e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+--------------------+\n",
            "|          name|          name|             gravity|\n",
            "+--------------+--------------+--------------------+\n",
            "|Luke Skywalker|      Alderaan|          1 standard|\n",
            "|Luke Skywalker|      Yavin IV|          1 standard|\n",
            "|Luke Skywalker|          Hoth|        1.1 standard|\n",
            "|Luke Skywalker|       Dagobah|                 N/A|\n",
            "|Luke Skywalker|        Bespin|1.5 (surface), 1 ...|\n",
            "|Luke Skywalker|         Endor|       0.85 standard|\n",
            "|Luke Skywalker|         Naboo|          1 standard|\n",
            "|Luke Skywalker|     Coruscant|          1 standard|\n",
            "|Luke Skywalker|        Kamino|          1 standard|\n",
            "|Luke Skywalker|      Geonosis|        0.9 standard|\n",
            "|Luke Skywalker|        Utapau|          1 standard|\n",
            "|Luke Skywalker|      Mustafar|          1 standard|\n",
            "|Luke Skywalker|      Kashyyyk|          1 standard|\n",
            "|Luke Skywalker|   Polis Massa|       0.56 standard|\n",
            "|Luke Skywalker|       Mygeeto|          1 standard|\n",
            "|Luke Skywalker|       Felucia|       0.75 standard|\n",
            "|Luke Skywalker|Cato Neimoidia|          1 standard|\n",
            "|Luke Skywalker|     Saleucami|                  NA|\n",
            "|Luke Skywalker|       Stewjon|          1 standard|\n",
            "|Luke Skywalker|        Eriadu|          1 standard|\n",
            "+--------------+--------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ghanging name of columns\n",
        "\n",
        "charactersDF\\\n",
        ".join(broadcast(planetsDF.withColumnRenamed('name', 'planet')))\\\n",
        ".select(col(\"name\"), col(\"planet\"), col(\"gravity\"))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrc1ighmHkmX",
        "outputId": "f4ff43bd-09ac-445a-da32-538d6e0471d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+--------------------+\n",
            "|          name|        planet|             gravity|\n",
            "+--------------+--------------+--------------------+\n",
            "|Luke Skywalker|      Alderaan|          1 standard|\n",
            "|Luke Skywalker|      Yavin IV|          1 standard|\n",
            "|Luke Skywalker|          Hoth|        1.1 standard|\n",
            "|Luke Skywalker|       Dagobah|                 N/A|\n",
            "|Luke Skywalker|        Bespin|1.5 (surface), 1 ...|\n",
            "|Luke Skywalker|         Endor|       0.85 standard|\n",
            "|Luke Skywalker|         Naboo|          1 standard|\n",
            "|Luke Skywalker|     Coruscant|          1 standard|\n",
            "|Luke Skywalker|        Kamino|          1 standard|\n",
            "|Luke Skywalker|      Geonosis|        0.9 standard|\n",
            "|Luke Skywalker|        Utapau|          1 standard|\n",
            "|Luke Skywalker|      Mustafar|          1 standard|\n",
            "|Luke Skywalker|      Kashyyyk|          1 standard|\n",
            "|Luke Skywalker|   Polis Massa|       0.56 standard|\n",
            "|Luke Skywalker|       Mygeeto|          1 standard|\n",
            "|Luke Skywalker|       Felucia|       0.75 standard|\n",
            "|Luke Skywalker|Cato Neimoidia|          1 standard|\n",
            "|Luke Skywalker|     Saleucami|                  NA|\n",
            "|Luke Skywalker|       Stewjon|          1 standard|\n",
            "|Luke Skywalker|        Eriadu|          1 standard|\n",
            "+--------------+--------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSEBVnVQlU52"
      },
      "source": [
        "## Exercise 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF4fyAaMlXsI"
      },
      "source": [
        "Check exercise 3. What join type are been used? Why?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbYUbaSMlXGc"
      },
      "source": [
        "After checking execution plan, execute the following instructions:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8HYt2Eylh4k"
      },
      "source": [
        "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", '0')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwEnVoVqnj7D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f01ab3e3-0848-4bd8-f266-399208d31013"
      },
      "source": [
        "spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxqgghUnlWe3"
      },
      "source": [
        "Execute again the query of the exercise 3\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3 query\n",
        "\n",
        "charactersDF\\\n",
        ".join(broadcast(planetsDF.withColumnRenamed('name', 'planet')))\\\n",
        ".select(col(\"name\"), col(\"planet\"), col(\"gravity\"))\\\n",
        ".show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKMwOxA_PNXV",
        "outputId": "52e63992-9957-43a6-ba75-69f3d8a16322"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+--------------------+\n",
            "|          name|        planet|             gravity|\n",
            "+--------------+--------------+--------------------+\n",
            "|Luke Skywalker|      Alderaan|          1 standard|\n",
            "|Luke Skywalker|      Yavin IV|          1 standard|\n",
            "|Luke Skywalker|          Hoth|        1.1 standard|\n",
            "|Luke Skywalker|       Dagobah|                 N/A|\n",
            "|Luke Skywalker|        Bespin|1.5 (surface), 1 ...|\n",
            "|Luke Skywalker|         Endor|       0.85 standard|\n",
            "|Luke Skywalker|         Naboo|          1 standard|\n",
            "|Luke Skywalker|     Coruscant|          1 standard|\n",
            "|Luke Skywalker|        Kamino|          1 standard|\n",
            "|Luke Skywalker|      Geonosis|        0.9 standard|\n",
            "|Luke Skywalker|        Utapau|          1 standard|\n",
            "|Luke Skywalker|      Mustafar|          1 standard|\n",
            "|Luke Skywalker|      Kashyyyk|          1 standard|\n",
            "|Luke Skywalker|   Polis Massa|       0.56 standard|\n",
            "|Luke Skywalker|       Mygeeto|          1 standard|\n",
            "|Luke Skywalker|       Felucia|       0.75 standard|\n",
            "|Luke Skywalker|Cato Neimoidia|          1 standard|\n",
            "|Luke Skywalker|     Saleucami|                  NA|\n",
            "|Luke Skywalker|       Stewjon|          1 standard|\n",
            "|Luke Skywalker|        Eriadu|          1 standard|\n",
            "+--------------+--------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT-AFIMvm43z"
      },
      "source": [
        "## Exercise 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9UBVU6ym9ue"
      },
      "source": [
        "1. Create a DataFrame from `species.csv`.\n",
        "2. Repartition the previous DataFrame to 100 partitions\n",
        "3. Repartition `characters` DataFrame to 100 partitions\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohStdyUGnRC0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv0AmHi926F7"
      },
      "source": [
        "## Exercise 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR6FPU3b29TP"
      },
      "source": [
        "Get the specie classification for each character. Select only the character name and its classification<br>\n",
        "Use DataFrames repartitioned previously\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zyuYbll3UrI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG81SgpY4P3t"
      },
      "source": [
        "## Exercise 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56fGSsmt4adO"
      },
      "source": [
        "1. Execute the following statement over the DataFrame built in exercise 6\n",
        "2. Check the difference in terms of rows distribution across all partitions\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFvUIbn93woD"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "classDF \\\n",
        "  .withColumn(\"partitionId\", spark_partition_id()) \\\n",
        "  .groupBy(\"partitionId\") \\\n",
        "  .count() \\\n",
        "  .orderBy(col(\"count\").desc()) \\\n",
        "  .show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io-BtgnHyKZ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}